"use strict";(self.webpackChunkop_sqlite=self.webpackChunkop_sqlite||[]).push([[307],{3409:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"tokenizers","title":"Custom Tokenizers","description":"Tokenizers are custom C functions that allow you to turn a stream of characters into \u201ctokens\u201d. Tokens can be anything you want, you can break on whitespaces, special characters, etc. They are meant to help you break the characters for full-text search queries to be more accurate.","source":"@site/docs/tokenizers.md","sourceDirName":".","slug":"/tokenizers","permalink":"/op-sqlite/docs/tokenizers","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tokenizers.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Libsql Support","permalink":"/op-sqlite/docs/libsql"},"next":{"title":"API Reference","permalink":"/op-sqlite/docs/api"}}');var i=t(4848),r=t(8453);const s={sidebar_position:7},a="Custom Tokenizers",c={},l=[];function d(e){const n={code:"code",h1:"h1",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"custom-tokenizers",children:"Custom Tokenizers"})}),"\n",(0,i.jsx)(n.p,{children:"Tokenizers are custom C functions that allow you to turn a stream of characters into \u201ctokens\u201d. Tokens can be anything you want, you can break on whitespaces, special characters, etc. They are meant to help you break the characters for full-text search queries to be more accurate."}),"\n",(0,i.jsx)(n.p,{children:"op-sqlite has a novel way for you to create your tokenizers."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Declare which tokenizers you want on the ",(0,i.jsx)(n.code,{children:"package.json"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'"op-sqlite": {\n\t// Leave whatever configuration you already have\n\t"fts5": true, // fts needs to be enabled\n\t"tokenizers": ["word_tokenizer"] // declare which tokenizers you will create\n}\n'})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Run ",(0,i.jsx)(n.code,{children:"pod install"}),". The podspec now contains a code generation step. It will create a ",(0,i.jsx)(n.code,{children:"c_sources"})," folder at the root of your project. It will create a ",(0,i.jsx)(n.code,{children:"tokenizers.h"})," file. DON\u2019T TOUCH THIS FILE. It will be overwritten every time. You need to create a ",(0,i.jsx)(n.code,{children:"c_sources/tokenizers.cpp"})," file. Here you need to provide your tokenizer implementation. The ",(0,i.jsx)(n.code,{children:"tokenizer.h"})," file contains the function declaration that will be executed when registering your tokenizer. In this case here is a sample ",(0,i.jsx)(n.code,{children:"tokenizers.cpp"})," implementation"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'#include "tokenizers.h"\n#include <cctype>\n#include <memory>\n#include <string>\n\nnamespace opsqlite {\n\nfts5_api *fts5_api_from_db(sqlite3 *db) {\n  fts5_api *pRet = 0;\n  sqlite3_stmt *pStmt = 0;\n\n  if (SQLITE_OK == sqlite3_prepare_v2(db, "SELECT fts5(?1)", -1, &pStmt, 0)) {\n    sqlite3_bind_pointer(pStmt, 1, (void *)&pRet, "fts5_api_ptr", NULL);\n    sqlite3_step(pStmt);\n  }\n  sqlite3_finalize(pStmt);\n  return pRet;\n}\n\nclass WordTokenizer {\npublic:\n  WordTokenizer() = default;\n  ~WordTokenizer() = default;\n};\n\n// Define `xCreate`, which initializes the tokenizer\nint wordTokenizerCreate(void *pUnused, const char **azArg, int nArg,\n                        Fts5Tokenizer **ppOut) {\n  auto tokenizer = std::make_unique<WordTokenizer>();\n  *ppOut = reinterpret_cast<Fts5Tokenizer *>(\n      tokenizer.release()); // Cast to Fts5Tokenizer*\n  return SQLITE_OK;\n}\n\n// Define `xDelete`, which frees the tokenizer\nvoid wordTokenizerDelete(Fts5Tokenizer *pTokenizer) {\n  delete reinterpret_cast<WordTokenizer *>(pTokenizer);\n}\n\n// Define `xTokenize`, which performs the actual tokenization\nint wordTokenizerTokenize(Fts5Tokenizer *pTokenizer, void *pCtx, int flags,\n                          const char *pText, int nText,\n                          int (*xToken)(void *, int, const char *, int, int,\n                                        int)) {\n  int start = 0;\n  int i = 0;\n\n  while (i <= nText) {\n    if (i == nText || !std::isalnum(static_cast<unsigned char>(pText[i]))) {\n      if (start < i) { // Found a token\n        int rc = xToken(pCtx, 0, pText + start, i - start, start, i);\n        if (rc != SQLITE_OK)\n          return rc;\n      }\n      start = i + 1;\n    }\n    i++;\n  }\n  return SQLITE_OK;\n}\n\nint opsqlite_word_tokenizer_init(sqlite3 *db, char **error,\n                         sqlite3_api_routines const *api) {\n  fts5_tokenizer wordtokenizer = {wordTokenizerCreate, wordTokenizerDelete,\n                                  wordTokenizerTokenize};\n\n  fts5_api *ftsApi = (fts5_api *)fts5_api_from_db(db);\n  if (ftsApi == NULL)\n    return SQLITE_ERROR;\n\n  return ftsApi->xCreateTokenizer(ftsApi, "word_tokenizer", NULL,\n                                  &wordtokenizer, NULL);\n}\n\n} // namespace opsqlite\n\n'})}),"\n",(0,i.jsxs)(n.p,{children:["You need to keep the namespace and the function signature intact. For now the ",(0,i.jsx)(n.code,{children:"sqlite3_api_routines"})," parameter will always be a null pointer."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Once you are done. You need to run ",(0,i.jsx)(n.code,{children:"pod install"})," again. It will then copy the files you created to the pod sources in order to compile ",(0,i.jsx)(n.code,{children:"op-sqlite"})," together with your new C++ code in one go."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["The code generation step is only implemented in Cocoapods. Every time you create/change a file inside of ",(0,i.jsx)(n.code,{children:"c_sources"})," you will need to do a ",(0,i.jsx)(n.code,{children:"pod install"})," to re-add the newly created files into the compilation process. This also applies for Android, at least the header file generation step. On your CI, you will also need to do a pod install even if your pods are cached, in order to copy the sources."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"You can then create a FTS5 virtual table with your tokenizer:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-tsx",children:"let db = open({\n  name: 'tokenizers.sqlite',\n  encryptionKey: 'test',\n});\n\n// inside your component or wherever you initialize your database\n// THIS IS SAMPLE CODE, use your head when creating your tables\nuseEffect(() => {\n  let setup = async () => {\n    await db.execute(\n      `CREATE VIRTUAL TABLE tokenizer_table USING fts5(content, tokenize = 'word_tokenizer');`\n    );\n\n    await db.execute('INSERT INTO tokenizer_table(content) VALUES (?)', [\n      'This is a test document',\n    ]);\n\n    const res = await db.execute(\n      'SELECT content FROM tokenizer_table WHERE content MATCH ?',\n      ['test']\n    );\n\n    console.warn(res);\n  };\n  setup();\n}, []);\n"})}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>a});var o=t(6540);const i={},r=o.createContext(i);function s(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);